---
title: "`AgreeClust`: implementing with R an agreement-based unsupervised clustering of ratings through a latent class regression modeling framework"
author: "Margot Brard, Sébastien Lê & David Causeur"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
    number_sections: true
    toc: true
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

In this vignette, we present the `AgreeClust` package, a package that considers a latent class regression modeling framework for highlighting the structure of disagreement among panels of raters involved in inquiries. At the moment, the package is able to take into account two common types of scales: binary ratings and continuous ratings. 

On the contrary to popular approaches used to study inter-rater agreement, the present method considers the ratings data provided by all raters when studying the structure of disagreement among the panel. More precisely, the structure of disagreement is captured through the profiles of residuals of a no-latent class regression model adjusted on the entire set of ratings, and can be visualized by using exploratory data analysis tools. The disagreement between two raters is then quantify in a concise way through the Euclidean distance between their respective profiles of residuals, this disagreement index being used as a basis to construct a dendrogram representing the structure of disagreement among the panel. The proper number of disagreed clusters among the panel of raters is then chosen by implementing a sequential strategy to test the significance of each $K$-clusters structure of disagreement. This modeling framework provides to the user a partition of the panel in several disagreed clusters of raters. Finally, the package allows the user to consolidate the previous partition of raters by using a partitioning algorithm, and to interpret the obtained clusters of raters by using covariates providing pieces of information about the raters themselves and/or about the stimuli rated during the experiment. The package also provides several `ggplot2`-type graphical tools to facilitate the interpretation of the structure of agreement/disagreement observed among the panel of raters.

Section 2 presents the installation of the package from GitHub repository. Section 3 presents the kinds of data that can be handle with the package. Section 4 introduces the global approach: the general latent class regression modeling framework and its use to perform the segmentation of the panel of raters, the consolidation of the obtained partition of raters, and the interpretation of the clusters by using covariates providing information about the raters or the stimuli. Sections 5 and 6 present respectively the adaptation of the global approach to binary ratings and continuous ratings. Artificial small pedagogic data sets are introduced as a motivating examples in these two last sections, and real data sets are briefly presented.

# Installing the package

The package is freely available for download online at https://github.com/MargotBr/AgreeClust. The user can get the current development version from GitHub in the following way:

```{r eval=FALSE}
install.packages("devtools") # only if the package has not been installed yet
devtools::install_github("MargotBr/AgreeClust", build_vignettes = TRUE)
library(AgreeClust)
```

```{r eval=FALSE}
library(AgreeClust)
```

```{r}
load("/Users/lma/ownCloud/R/AgreeClust/data/pedagdataBin.rda")
load("/Users/lma/ownCloud/R/AgreeClust/data/pedagdataCont.rda")
source("/Users/lma/ownCloud/R/AgreeClust/R/AgreeClustBin.R")
source("/Users/lma/ownCloud/R/AgreeClust/R/AgreeClustCont.R")
source("/Users/lma/ownCloud/R/AgreeClust/R/GlmSum.R")
source("/Users/lma/ownCloud/R/AgreeClust/R/plot.AgreeClust.R")
source("/Users/lma/ownCloud/R/AgreeClust/R/print.AgreeClust.R")
```

# Using the proper format of data

The package is able to manage matrices of dimensions $S \times R$, where $S$ denotes the number of strimuli rated during the experiment and $R$ denotes the number of raters who were involved in the experiment. At the intersection of the line $s$ and the column $r$ is the rating of the $s$-th stimulus by the $r$-th rater $Y_{sr}$.

![](Datanoext.jpeg)

If external information about the stimuli and the raters was collected during the experiment, the previous data set is supplemented by these covariates. More precisely, covariates providing information about the stimuli are added to the previous data set as supplementary columns; and covariates providing information about the raters are added to the previous data set as supplementary lines. The intersection cells between these covariates are filled by missing data.

![](Dataext.jpeg)

# Understanding the global approach

We propose hereafter a general modeling framework for the whole agreement data that introduces both stimuli and raters propensity scores by estimating the marginal distributions of ratings across all raters and all stimuli and not pairwise agreement tables, as this is done usually in inter-rater agreement studies. In the former regression framework, a latent modular structure of disagreement is also introduced as a particular $stimulus \times rater$ interaction structure.

In the following, it will be assumed that the panel ${\cal C} = [1;R]$ of raters, where $R \geq 2$ is the number of raters, is partitioned into $K$ clusters ${\cal C}_{k}, k=1, \ldots, K$, with $1 \leq K \leq R$, $\bigcup_{k} {\cal C}_{k}={\cal C}$ and, for all $k \neq k'$, ${\cal C}_{k} \cap {\cal C}_{k'}=\emptyset$. The number of raters in cluster ${\cal C}_{k}$ will hereafter be denoted $R_{k}$, with $R_{k} \geq 2$. Let $Y_{srk}$ denote the rating of the $s$-th stimulus, with $s=1,\ldots,S$, by the $r$-th rater in cluster ${\cal C}_{k}$. The following latent class regression model is assumed:

<center>$g(Y_{srk})=\mu+\alpha_{s}+\beta_{r|k}+\delta_{k}+(\alpha\delta)_{sk}$ (1)</center>

where $g$ is the link function, $\alpha_{s}$ and $\beta_{r|k}$ are main effect parameters for the stimuli and the raters respectively, the notation $r|k$ being used here to indicate that the $rater$ effect is embedded into the $latent \ class$ effect. Those parameters $(\alpha_{s})_{s=1,\ldots,S}$ can be referred to as stimulus propensity scores, whereas, for all $k$, $(\beta_{r|k})_{r=1,\ldots,R_{k}}$ can be viewed as cluster-specific rater propensity scores. Analogously, $\delta_{k}$ is the propensity score for cluster ${\cal C}_{k}$ and $(\alpha\delta)_{sk}$ stands for the $stimulus \times cluster$ interaction effect.

Note that the following additive model is obtained as a special case of the model (1) when no latent class structure (i.e. $K=1$) is assumed:

<center>$g(Y_{srk})=\mu+\alpha_{s}+\beta_{r}$</center>

Discussing the relevance of propensity scores in models (1) and (2) is out of the purpose of the present vignette. Anyway, the package allows the user to decide to consider or not the stimuli-specific parameters and/or the raters-specific parameters when modeling the ratings provided by the panel.

## Constructing the dendrogram representing the structure of disagreement among the panel

Since a perfect fit of model (2) would mean that the rating of a given stimulus does not vary from one rater to another, it will be considered as a *perfect agreement* model. Accordingly, model (1) can be viewed as a finite mixture of within-cluster *perfect agreement* models in the sense that model (2) holds within each cluster with cluster-specific propensity scores. Therefore, model (2) departs from the *perfect agreement* model by capturing a possible between-clusters disagreement on the ratings of the $s$-th stimulus through the $cluster \times stimulus$ interaction parameters.

As ratings data have no replication, the two-way interaction $cluster \times stimulus$ is a part of the error term of model (2). This is why this error term can be used to model the heterogeneity in the ratings provided by the raters; the possible pattern of heterogeneity between the ratings being defined as the gap between the observed values and the values adjusted with model (2). Consequently, the possible pattern of disagreement between the $R$ raters among the panel can be seen as a discrepancy between the observed values and the values adjusted with the logistic regression model of perfect agreement (2), this discrepancy being measurable by the residuals of model (2):

<center>$\hat{\varepsilon}_{sr}$</center>

Two raters having the same $S-$profile of residuals $\hat{\varepsilon}_{r}=(\hat{\varepsilon}_{r1},\ldots,\hat{\varepsilon}_{rS})'$ would depart from the full agreement model the same way, and, consistently should appear in the same disagreement cluster. Therefore, we propose to consider the Euclidean distance $d^{\scriptscriptstyle \text{res}}_{rr'}$ between the profiles of residuals as a dissimilarity index between raters $r$ and $r'$:

<center>$d^{\scriptscriptstyle \text{res}}_{rr'} = \sqrt{\sum\limits_{s=1}^{S}(\hat{\varepsilon}_{sr} - \hat{\varepsilon}_{sr'} )^{2}}$</center>

Moreover, since the deviance residuals $\hat{\varepsilon}_{rs}$ are approximately distributed according to a standard normal distribution, any model-based or not clustering algorithm applied on the dissimilarity matrix $D^{\scriptscriptstyle \text{res}}$ with generic term $d^{\scriptscriptstyle \text{res}}_{rr'}$ can be used to extract modules of raters sharing the same pattern of rating for the stimuli. 

Agglomerative hierarchical clustering algorithms is favored to extract the latent class disagreement structure from the dissimilarity matrix $D^{\scriptscriptstyle \text{res}}$. Indeed, these algorithms provide a sequence of nested partitions of the raters deduced from a dendrogram, starting from a full consensus among all raters (one cluster) to the extreme situation of a complete disagreement with as many clusters as raters. In the following, the former Ward's algorithm is used to infer on the latent class disagreement pattern.

In the next section, a fitting procedure is proposed with ad-hoc testing methods for the significance of the latent class disagreement model.

## Cutting the dendrogram at the proper level

Sequentially testing the significance of a $(K+1)-$clusters structure embedded in a $K-$clusters super-structure can be addressed by analysis of model comparison tests in the general framework of model (1).

For a fixed number, say $K$, of clusters, fitting the $K-$ latent class model (1) involves three steps: first, maximum-likelihood fitting of *perfect agreement* model (1); then, extraction of the best $K$-clusters partition using the Ward's algorithm applied to the Euclidean distance matrix of residuals $D^{\scriptscriptstyle \text{res}}$; and finally, maximum-likelihood fitting of model (1), based on the former $K-$ latent class $stimulus \times rater$ interaction pattern. Retracing the dendrogram resulting from the Ward's algorithm downward, starting from its top node, where all raters are classified in a unique cluster, and moving down it leads to a sequence of nested models (1) with increasing number of latent classes. Therefore, determination of the proper number of latent classes can be handled by sequential model comparison tests for the significance of the $(K+1)-$ latent class model w.r.t the $K-$ latent class model. Note that the null distribution of the test statistics has to be adapted to the fact that the latent class interaction structure is inferred from the data. We propose to approximate this null distribution by a Monte-Carlo method, based on simulations of the null $K-$ latent class model (1) as estimated at the previous step. When the null hypothesis cannot longer be rejected, $K$ is used as the proper number of clusters of raters among the panel.

The $p-$value of each test is provided at the corresponding level of the dendrogram. If the 2-latent class model is not significant w.r.t the no-latent class model, that means that there is no necessity to cut the dendrogram and to segment the panel of raters. This aspect can highlights two kinds of situations: (1) the ratings provided by the raters are too heterogeneous to highlight consistent sub-clusters of raters; or (2) the ratings provided by the raters are too homogeneous to highlight consistent sub-clusters of raters, meaning that the panel of raters is composed of one homogeneous cluster of raters who provided consensual ratings. Naturally, this aspect is of the main interest in the context of studying the agreement/disagreement among the panel of raters. With the aim of providing this information, we propose to implement a statistical test to evaluate the goodness of fit of the no-latent class model (2). If the null hypothesis is not rejected, that means that the panel of raters rated the set of stimuli in a consensual way. The $p-$value of this test is provided at the top node of the dendrogram (only if a no-latent class sturcture is found).
 
## Consolidating the partition of raters

Once the partition of raters is defined, it can been consolidated by introducing it as the initial partition of a partitioning algorithm. More precisely, in this case, a $K-$means algorithm is implemented. In practice, at each step of this algorithm, each rater in affected to the cluster with the nearest center of gravity, serving as a prototype of the cluster. The partition resulting from this algorithm is finally conserved. In practice, the initial partition is never entirely replaced, but rather improved or *consolidated*.

## Interpreting the clusters of raters

Once the final partition of raters is defined, clusters are described by information about the raters such as the percentage of raters in each cluster or the parangon of each cluster (i.e. the rater the nearest of the center of gravity of the cluster, who can be defined as the rater the most representative of the cluster). Moreover, if external information about the raters and/or about the stimuli are present in the data set, these covariates can be used to supplement the interpretation of the clusters of raters.

### Interpreting clusters by using external information about the raters

In some situations, supplementary information on the raters who participated to the experiment is available. These pieces of information often represent identity characteristics about the raters such as their gender, their age, their occupation, their level of expertise and so forth; but they can also represent habit characteristics. With the aim of characterizing the clusters of raters by using these pieces of information, univariate analyses are used to study the relationships between the clusters and the supplementary variables available about the raters. These univariate analyses depend on the type of the supplementary variables (i.e. continuous or categorical variables). They are described precisely in Husson et al. (2011) and implemented in the `FactoMineR` package (Lê, Josse & Husson, 2008). 

#### Describing clusters by the values of a continuous variable describing the raters

First, the global effect of the *Cluster* variable on the continuous variable $X$ describing the rater is studied through the global test of an analysis of variance model. If the global effect of the *Cluster* variable on the continuous variable $X$ is significant, the effect of each category of the *Cluster* variable is then studied independently. More precisely, for each category of the *Cluster* variable (i.e. for each cluster of raters), a $v$-test (a test value) is calculated as follows:

\begin{equation*}
  v\text{-test} = \frac{\bar{x_k}-\bar{x}}{\sqrt{\frac{s^2}{J_k}\left(\frac{R-R_k}{R-1}\right)}}
\end{equation*}

where $\bar{x_k}$ stands for the average of the given continuous variable $X$ for the raters of cluster ${\cal C}_{k}$, $\bar{x}$ stands for the average of the given continuous variable $X$ for all the raters of the panel, and $R_k$ stands for the number of raters in cluster ${\cal C}_{k}$. 

This value $v$-test is used to test the following null hypothesis: \emph{$H_0$: the values of the continuous variable $X$ taken by the raters of cluster ${\cal C}_{k}$ are selected at random from all of the possible values of the continuous variable $X$}. We therefore consider the random variable $\bar{X_k}$, average of the values of $X$ taken by the raters in cluster ${\cal C}_{k}$. Its expected value and variance are:

<center>$\mathbb{E}(\bar{X_k})=\bar{x}$ and $\mathbb{V}(\bar{X_k})=\frac{s^2}{R_k} \times \frac{R-R_k}{R-1}$</center>

The $v$-test can therefore be considered a *standardized* deviation between the average of $X$ in the $k$-th cluster and the general average. Among other things, we can attribute a probability to the $v$-test. If, among the $R$ raters, the continuous variable $X$ is normally distributed according to the null hypothesis, the $\bar{X_k}$ distribution is as follows:

\begin{equation*}
  \bar{X_k}=\mathcal{N} \left(\bar{x},\frac{s}{\sqrt{R_k}}\sqrt{\frac{R-R_k}{R-1}} \right)
\end{equation*}

If the null hypothesis $H_0$ is accepted, that means that the average of the continuous variable for cluster ${\cal C}_{k}$ equals the general average among the panel; and that, in other words, the continuous variable does not characterize cluster ${\cal C}_{k}$. On the contrary, if the null hypothesis $H_0$ is rejected, that means that the continuous variable characterizes cluster ${\cal C}_{k}$. The sign of the $v$-test is then used to determine if the values of the continuous variable taken by the raters of cluster ${\cal C}_{k}$ are high (positive $v$-test) or low (negative $v$-test) w.r.t. the observations made on the entire panel.

#### Describing clusters by the levels of a categorical variable describing the raters

First, the global effect of the *Cluster* variable on the categorical variable $Q$ describing the rater is studied through a chi-square test of independence. If the *Cluster* variable and the categorical variable $Q$ are not significantly independent, the effect of each category of the *Cluster* variable is then studied independently. More precisely, for each category of the *Cluster* variable (i.e. for each cluster of raters) and for a given level (noticed $q$) of the categorical variable $Q$, the aim is to determine if cluster ${\cal C}_{k}$ is characterized by this given level $q$ or not. To do so, the proportion $R_{kq}/R_{k}$ corresponding to the proportion of raters among cluster ${\cal C}_{k}$ who take the given level $q$ is compared to the proportion $R_{q}/J$ corresponding to the proportion of raters among the entire panel who take the given level $q$. These two proportions are equal under the null hypothesis of independence $H_0$: 

\begin{equation*}
  \frac{R_{kq}}{R_{k}}=\frac{R_{q}}{R}
\end{equation*}

$R_{k}$ raters are randomly selected among $R$. We shall focus on the random variable $N$ equaled to the number $R_{kq}$ of occurrences of raters who have the characteristic $q$, while it must be remembered that their sample size within the population is $R_{q}$. Under the null hypothesis $H_0$, the random variable $N$ follows the hypergeometric distribution $\mathcal{H}(R,R_{q},R_{k})$. The probability of having a more extreme value than the observed value can therefore be calculated. 

If the null hypothesis $H_0$ is accepted, that means that the level $q$ does not characterize cluster ${\cal C}_{k}$. On the contrary, if the null hypothesis $H_0$ is rejected, that means that the level $q$ characterizes cluster ${\cal C}_{k}$. The sign of the $v$-test is then used to determine if level $q$ is overrepresented (positive $v$-test) or underrepresented (negative $v$-test) in cluster ${\cal C}_{k}$ w.r.t. the observations made on the entire panel.

### Interpreting clusters by using external information about the stimuli

In some situations, supplementary information on the stimuli rated during the experiment is available. If the stimuli are industrial goods, these pieces of information can represent intrinsic characteristics about the stimuli such as the composition, rheological properties, psycho-chemical properties, sensory properties and so forth; but they can also represent extrinsic characteristics about the stimuli such as their packaging. With the aim to characterize the clusters of raters by using these pieces of information, univariate analyses are used to study the relationship between the clusters and the supplementary variables available about the stimuli. These univariate depend on the type of the supplementary variables (i.e. continuous or categorical variables). 

#### Describing clusters by the values of a quantitative variable describing the stimuli

The interaction effect between the *Cluster* variable and the given continuous variable $X$ on the rating is studied through the following regression model involving sum contrasts:

<center>$g(Y_{kl})=\mu+\delta_{k}+\beta x_{kl}+\sigma_{k}x_{kl}$ with $\sum\limits_{k=1}^{K}\delta_{k}=0$ and $\sum\limits_{k=1}^{K}\sigma_{k}=0$ </center>

where $g$ is the link function; $Y_{kl}$ stands for the $l-$th rating provided by cluster ${\cal C}_{k}$; $\delta_{k}$ stands for the specific effect of cluster ${\cal C}_{k}$; $\beta$ stands for the effect of the continuous variable $X$; and $\sigma_{k}$ stands for the specific effect of the continuous variable $X$ for cluster ${\cal C}_{k}$.

If the global effect of the interaction between the cluster and the continuous variable $X$ is significant, that means that the effect of the quantitative variable $X$ on the rating is not the same from one cluster to the other. 

To highlight these aspects, the significance of the coefficients $\sigma_{k}$ is studied. Indeed, if the coefficient $\sigma_{k}$ is significant, that means that the impact of the values of the continuous $X$ on the rating is significantly different for cluster ${\cal C}_{k}$ w.r.t. the observations made on the entire panel. If this is the case, that means that the impact of the continuous variable $X$ on the rating characterizes cluster ${\cal C}_{k}$. The sign of the coefficient is then used to determine if large values of the continuous variable $X$ led to high ratings (positive coefficient) or low ratings (negative coefficient) in cluster ${\cal C}_{k}$ w.r.t. the observations made on the entire panel.

#### Describing clusters by the values of a categorical variable describing the stimuli

The interaction effect between the *Cluster* variable and the given categorical variable $Q$ on the rating is studied through the following regression model involving sum contrasts:

<center>$g(Y_{qkl})=\mu+\omega_{q}+\delta_{k}+(\omega\delta_{qk})$ with $\sum\limits\limits_{q=1}^{Q}\omega_{q}=0$, $\sum\limits_{k=1}^{K}\delta_{k}=0$ and $\sum\limits_{q=1}^{Q}\sum\limits_{k=1}^{K}(\omega\delta)_{qk}=0$ </center>

where $g$ is the link function; $Y_{qkl}$ stands for the $l-$th rating provided by cluster ${\cal C}_{k}$ for a stimulus with the characteristic $q$ of the categorical variable $Q$; $\omega_{q}$ stands for the specific effect of the characteristic $q$; $\delta_{k}$ stands for the specific effect of cluster ${\cal C}_{k}$; and $(\omega\delta)_{qk}$ stands for the specific effect of the characteristic $q$ for cluster ${\cal C}_{k}$.

If the global effect of the interaction between the cluster and the categorical variable $Q$ is significant, that means that the effect of the levels of the categorical variable $Q$ on the rating is not the same from one cluster to the other.

To highlight these aspects, the significance of the coefficients $(\sigma\delta)_{qk}$ is studied. Indeed, if the coefficient $(\omega\delta)_{qk}$ is significant, that means that the impact of the characteristic $q$ on the rating is significantly different for cluster ${\cal C}_{k}$ w.r.t. the observations made on the entire panel. If this is the case, that means that the impact of the characteristic $q$ on rating characterizes cluster ${\cal C}_{k}$. The sign of the coefficient is then used to determine if a presence of the characteristic $q$ led to high ratings (positive coefficient) or low ratings (negative coefficient) in cluster ${\cal C}_{k}$ w.r.t. the observations made on the entire panel.

# Adapting the method to binary ratings

The `AgreeClustBin` function of the package is able to deal with binary ratings. The function considers a logistic latent class regression modeling for the agreement-based unsupervised clustering of a set of binary ratings:

<center> $g(y) = logit(\mathbb{P}(y = 1))$ </center>

For implementing the cutting strategy of the dendrogram, the Likelhood-Ratio Test (LRT) is used as the statistic test to test the significance of the $(K+1)-$ latent class model w.r.t the $K-$ latent class model.
 
The help page of the functions can be accessed with this code:

```{r}
help(AgreeClustBin)
```


To illustrate the outputs and graphs of the function, let's use a small pedagogic data set named *pedagdataBin*. This data set refers to the ratings of 8 stimuli provided by a panel of 20 raters. Ratings data are supplemented by covariates providing information about the stimuli and the raters. The columns 21, 22, 23, 24, and 25 provide information about the stimuli: *Citrus fruits intensity* (continuous), *Vanilla intensity* (continuous), *Wood intensity* (continuous), *Lotus intensity* (continuous), and *Packaging* which is either the current one or a prototype (categorical). The lines 9, 10, 11 provide information about the raters: *Gender* (categorical), *Age bracket* (categorical), *Frequency of use* (categorical). The code to import and visualize this data set is:

```{r}
data(pedagdataBin)
pedagdataBin
```

As shown on the help page, the function parallelizes by default the computation of the null LRT distribution for cutting the dendrogram (in this case, a file denoted *TestDendrogram_processing.txt* is automatically created in the working directory to access the processing status). Moreover, the function approximates by default the null LRT distribution by using the Satterthwaite's approximation. Finally, the function uses by default the following other important arguments:

- `dta`, specifying the name of the data set to be used;
- `model = "Rating ~ Rater + Stimulus"`, meaning that both the raters propensities and the stimuli propensities are taken into account when modeling the ratings data. Other available possibilities are `"Rating ~ Rater"` (in this case, the disagreement index is similar to the Cohen's kappa $\kappa$) or `"Rating ~ 1"` (in this case, the disagreement index is similar to the simple matching coefficient);
- `consol = TRUE`, meaning that the partition of raters is consolidated using a partitioning algorithm; 
- `id.info.rater = NULL`, `type.info.rater = NULL`, `id.info.stim = NULL`, and `type.info.stim = NULL`, meaning that no covariates about either the raters nor the stimuli are available in the data set. 

As the data set contains covariates about the raters and the stimuli, the last arguments have to be modified in the following way:

- `id.info.rater = c(9, 10, 11)`, meaning that the 3 covariates about the raters are accessible in lines 9, 10, and 11 of the data set;
- `type.info.rater = rep("cat", 3)`, meaning that the 3 covariates about the raters are categorical;
- `id.info.rater = c(21, 22, 23, 24, 25)`, meaning that the 5 covariates about the stimuli are accessible in columns 21, 22, 23, 24, and 25 of the data set;
- `type.info.stim = c(rep("cont", 4), "cat")`, meaning that the 4 first covariates about the stimuli are continuous and that the last one is categorical.

Finally, the code to perform the clustering is:

```{r eval=FALSE}
res.pedag <- AgreeClustBin(dta = pedagdataBin, id.info.rater = 9 : nrow(pedagdataBin), type.info.rater = rep("cat", 3), id.info.stim = 21 : ncol(pedagdataBin), type.info.stim = c(rep("cont", 4), "cat"))
```

```{r echo=FALSE, message=FALSE}
res.pedag <- AgreeClustBin(dta = pedagdataBin, id.info.rater = 9 : nrow(pedagdataBin), type.info.rater = rep("cat", 3), id.info.stim = 21 : ncol(pedagdataBin), type.info.stim = c(rep("cont", 4), "cat"), graph = FALSE)
```

The first object returned by the function is the matrix containing the profiles of deviance residuals. The larger the residual (in absolute value), the larger the departure from the situation of *perfect agreement* (cf. model (2)). This object can be accessed with this code:

```{r eval=FALSE}
res.pedag$profiles.residuals
```

```{r echo=FALSE}
round(res.pedag$profiles.residuals, 1)
```

The second object returned by the function is the disagreement matrix between raters. The larger the value in this matrix, the more important the disagreement between the two corresponding raters. This object can be accessed with this code:

```{r eval=FALSE}
res.pedag$mat.disag
```

```{r echo=FALSE}
round(res.pedag$mat.disag, 1)
```

The first graph created by the function shows the clustering process applied to this disagreement matrix. The dendrogram representing the structure of disagreement is presented at the top of the graph. The $p-$values associated to the different levels of its hierarchy show that two clusters of raters exist among the panel, as the $3-$ latent class model is not significant w.r.t the $2-$ latent class model. The consolidation step, whose the result is presented at the bottom of the graph, did not modify the partition of clusters. Finally, we can say that this panel is composed of two disagreed clusters: the first ten raters (cluster 1) against the last ten raters (cluster 2).

```{r echo=FALSE, fig.width=8, dpi=400, fig.height=8, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "seg", col.clust = c("#42B983", "#F36170"))
```

The clusters can be colored according to new colors in this plot. To do so, the following code is used:

```{r fig.width=8, dpi=400, fig.height=8, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "seg", col.clust = c("#FF8379", "#009193"))
```

The results of the clustering process ($p-$values associated to the test of the significance of each $K-$ clusters structure, number of clusters of raters found, and the final partition of raters) can be accessed with this code:

```{r}
res.pedag$pval.dendro
res.pedag$nb.clust.found
res.pedag$partition # consolidated in this example
```

The second graph created by the function shows the multidimensional representation of the structure of disagreement observed among the panel. This representation is obtained by submitting the $20 \times 8$ matrix contained in the object *res.pedag$profiles.residuals* to a Principal Components Analysis (PCA). PCA provides two main representations: a representation of the individuals (i.e. a representation of the 20 raters) and a representation of the variables (i.e. a representation of the 8 stimuli). On the representation of the raters, two raters are distant if they present a high disagreement. As these two representations are related to each other, the representation of the raters has to be interpreted regarding to the representation of the stimuli. This may be expressed as follows: raters are on the same side as the stimuli for which they gave a '1' rating, and opposite of the gestures for which they gave a '0' rating. 

In the present example, cluster 1 is characterized by '1' ratings for stimuli *Stim5*, *Stim6*, *Stim7*, and *Stim8*; and by '0' ratings for stimuli *Stim1*, *Stim2*, *Stim3*, and *Stim4*. On the contrary, cluster 2 is characterized by '0' ratings for stimuli *Stim5*, *Stim6*, *Stim7*, and *Stim8*; and by '1' ratings for stimuli *Stim1*, *Stim2*, *Stim3*, and *Stim4*.

```{r echo=FALSE, fig.width=8, dpi=400, fig.height=5, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", col.clust = c("#42B983", "#F36170"))
```

In the present example, the percentage of variability explained by the first factorial plane is $67.12\%+16.87\%=83.99\%$. This percentage is high enough to interpret the structure of disagreement according to this first factorial plane only. Howerver, is some situations, the user will have to interpret more dimensions of disagreement. To do so, the user can access all the results of the PCA as provided by the `PCA` function of the `FactoMineR` package (cf. help page of this function if needed). These results can be accessed with this code:

```{r}
res.pedag$res.pca
```

We can draw a bar plot with the eigenvalues of PCA with the following code:

<center>
```{r fig.width=6, fig.height=3, dpi=400}
barplot(res.pedag$res.pca$eig[, 1], main = "Eigenvalues", names.arg = paste0("Dim", 1 : nrow(res.pedag$res.pca$eig)))
```
</center>

This graph allows to detect the number of dimensions interesting for the interpretation of the structure of disagreement. The user can then plot the graph for the other interesting dimensions, let's say the third and the fourth dimensions (even if in our case, they should not be interpreted):

```{r eval=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", axis = c(3, 4))
```

```{r echo=FALSE, fig.width=8, dpi=400, fig.height=5, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", axis = c(3, 4), col.clust = c("#42B983", "#F36170"))
```

The `plot.AgreeClust` allows to plot the multidimensional representation of the structure of disagreement in an interative way. By moving the cursor on a point, several pieces of information are printed:

```{r eval=FALSE, fig.width=8, dpi=400, fig.height=6, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", interact = TRUE)
```

```{r echo=FALSE, fig.width=10, fig.height=6, warning=FALSE, message=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", interact = TRUE, col.clust = c("#42B983", "#F36170"), vignette = TRUE)
```

Finally, the function provides an automatic description of the clusters of raters. This description can be accessed with this code: 

```{r results=FALSE}
res.pedag$charact.clust
```

As shown on the following output, cluster 1 is composed of 10 raters (50/% of the panel) and the most representative rater of this cluster is *Subj7*. In this cluster, and relatively to the average, women and raters between 21 and 30 years old are overrepresented; while men and raters who assessed their frequency of use of the category of product at 3/10 are underrepresented. Relatively to the average, raters of this cluster present a higher propensity to give a '1' rating to stimuli presenting a high intensity of citrus fruits flavor and to stimuli with the prototype packaging; while they present a lower propensity to give a '1' rating to stimuli presenting a high intensity of wood flavor and to stimuli with the current packaging:

```{r echo=FALSE}
res.pedag$charact.clust[[1]]
```

As there is only two clusters of raters in this example, the interpretation of cluster 2 is the opposite to those of cluster 1:

```{r echo=FALSE}
res.pedag$charact.clust[[2]]
```

A real data set of binary ratings is also available in the help page of the package. This data set corresponds to data obtained during an experiment where 39 videos of culinary gestures (oysters opening gestures) have been evaluated on a binary scale, by 72 participants, according to their representativeness of the complex concept of 'good gesture' (1) or not (0). However, as the computation of the tests for the significance of the levels of the dendrogram can be time-consuming, its analysis is not presented in this vignette. This analysis can be accessed with this code:

```{r eval=FALSE}
data(ggdata)
res.gg <- AgreeClustBin(dta = ggdata, model = "Rating ~ Rater + Stimulus", id.info.rater = 40 : nrow(ggdata), type.info.rater = rep("cat", 4), id.info.stim = 73 : ncol(ggdata), type.info.stim = c(rep("cat", 3), rep("cont", 11)))
res.gg
```

# Adapting the method to continuous ratings

The `AgreeClustBin` function of the package is able to deal with continuous ratings. The function considers a latent class regression modeling for the agreement-based unsupervised clustering of a set of continuous ratings:

<center> $g(y) = y$ </center>

For implementing the cutting strategy of the dendrogram, the F statistic is used as the statistic test to test the significance of the $(K+1)-$ latent class model w.r.t the $K-$ latent class model.
 
The help page of the functions can be accessed with this code:

```{r}
help(AgreeClustCont)
```

To illustrate the outputs and graphs of the function, let's use a small pedagogic data set named *pedagdataCont*. This data set refers to the ratings of 8 stimuli provided by a panel of 20 raters. Ratings data are supplemented by covariates providing information about the stimuli and the raters. The columns 21, 22, 23, 24, and 25 provide information about the stimuli: *Citrus fruits intensity* (continuous), *Vanilla intensity* (continuous), *Wood intensity* (continuous), *Lotus intensity* (continuous), and *Packaging* which is either the current one or a prototype (categorical). The lines 9, 10, 11 provide information about the raters: *Gender* (categorical), *Age bracket* (categorical), *Frequency of use* (categorical). The code to import and visualize this data set is:

```{r}
data(pedagdataCont)
pedagdataCont
```

As shown on the help page, the function parallelizes by default the computation of the null F distribution for cutting the dendrogram (in this case, a file denoted *TestDendrogram_processing.txt* is automatically created in the working directory to access the processing status). Moreover, the function uses by default the following other important arguments:

- `dta`, specifying the name of the data set to be used;
- `model = "Rating ~ Rater + Stimulus"`, meaning that both the raters propensities and the stimuli propensities are taken into account when modeling the ratings data (in this case, the disagreement index is similar to the Euclidean distance between the raw ratings once they have been centered by rater). Other available possibilities are `"Rating ~ Rater"` (in this case, the disagreement index is also similar to the Euclidean distance between the raw ratings once they have been centered by rater) or `"Rating ~ 1"` (in this case, the disagreement index is similar to the Euclidean distance between the raw ratings);
- `consol = TRUE`, meaning that the partition of raters is consolidated using a partitioning algorithm; 
- `id.info.rater = NULL`, `type.info.rater = NULL`, `id.info.stim = NULL`, and `type.info.stim = NULL`, meaning that no covariates about either the raters nor the stimuli are available in the data set. 

As the data set contains covariates about the raters and the stimuli, the last arguments have to be modified in the following way:

- `id.info.rater = c(9, 10, 11)`, meaning that the 3 covariates about the raters are accessible in lines 9, 10, and 11 of the data set;
- `type.info.rater = rep("cat", 3)`, meaning that the 3 covariates about the raters are categorical;
- `id.info.rater = c(21, 22, 23, 24, 25)`, meaning that the 5 covariates about the stimuli are accessible in columns 21, 22, 23, 24, and 25 of the data set;
- `type.info.stim = c(rep("cont", 4), "cat")`, meaning that the 4 first covariates about the stimuli are continuous and that the last one is categorical.

Finally, the code to perform the clustering is:

```{r eval=FALSE}
res.pedag <- AgreeClustCont(dta = pedagdataCont, id.info.rater = 9 : nrow(pedagdataCont), type.info.rater = rep("cat", 3), id.info.stim = 21 : ncol(pedagdataCont), type.info.stim = c(rep("cont", 4), "cat"))
```

```{r echo=FALSE, message=FALSE}
res.pedag <- AgreeClustCont(dta = pedagdataCont, id.info.rater = 9 : nrow(pedagdataCont), type.info.rater = rep("cat", 3), id.info.stim = 21 : ncol(pedagdataCont), type.info.stim = c(rep("cont", 4), "cat"), graph = FALSE)
```

The first object returned by the function is the matrix containing the profiles of residuals. The larger the residual (in absolute value), the larger the departure from the situation of *perfect agreement* (cf. model (2)). This object can be accessed with this code:

```{r eval=FALSE}
res.pedag$profiles.residuals
```

```{r echo=FALSE}
round(res.pedag$profiles.residuals, 1)
```

The second object returned by the function is the disagreement matrix between raters. The larger the value in this matrix, the more important the disagreement between the two corresponding raters. This object can be accessed with this code:

```{r eval=FALSE}
res.pedag$mat.disag
```

```{r echo=FALSE}
round(res.pedag$mat.disag, 1)
```

The first graph created by the function shows the clustering process applied to this disagreement matrix. The dendrogram representing the structure of disagreement is presented at the top of the graph. The $p-$values associated to the different levels of its hierarchy show that two clusters of raters exist among the panel, as the $3-$ latent class model is not significant w.r.t the $2-$ latent class model. The consolidation step, whose the result is presented at the bottom of the graph, did not modify the partition of clusters. Finally, we can say that this panel is composed of two disagreed clusters: the first ten raters (cluster 1) against the last ten raters (cluster 2).

```{r echo=FALSE, fig.width=8, dpi=400, fig.height=8, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "seg", col.clust = c("#42B983", "#F36170"))
```

The clusters can be colored according to new colors in this plot. To do so, the following code is used:

```{r fig.width=8, dpi=400, fig.height=8, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "seg", col.clust = c("#FF8379", "#009193"))
```

The results of the clustering process ($p-$values associated to the test of the significance of each $K-$ clusters structure, number of clusters of raters found, and the final partition of raters) can be accessed with this code:

```{r}
res.pedag$pval.dendro
res.pedag$nb.clust.found
res.pedag$partition # consolidated in this example
```

The second graph created by the function shows the multidimensional representation of the structure of disagreement observed among the panel. This representation is obtained by submitting the $20 \times 8$ matrix contained in the object *res.pedag$profiles.residuals* to a Principal Components Analysis (PCA). PCA provides two main representations: a representation of the individuals (i.e. a representation of the 20 raters) and a representation of the variables (i.e. a representation of the 8 stimuli). On the representation of the raters, two raters are distant if they present a high disagreement. As these two representations are related to each other, the representation of the raters has to be interpreted regarding to the representation of the stimuli. This may be expressed as follows: raters are on the same side as the stimuli for which they gave a high rating, and opposite of the gestures for which they gave a low rating. 

In the present example, cluster 1 is characterized by high ratings for stimuli *Stim5*, *Stim6*, *Stim7*, and *Stim8*; and by low ratings for stimuli *Stim1*, *Stim2*, *Stim3*, and *Stim4*. On the contrary, cluster 2 is characterized by low ratings for stimuli *Stim5*, *Stim6*, *Stim7*, and *Stim8*; and by high ratings for stimuli *Stim1*, *Stim2*, *Stim3*, and *Stim4*.

```{r echo=FALSE, fig.width=8, dpi=400, fig.height=5, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", col.clust = c("#42B983", "#F36170"))
```

In the present example, the percentage of variability explained by the first factorial plane is $65.43\%+16.59\%=82.02\%$. This percentage is high enough to interpret the structure of disagreement according to this first factorial plane only. Howerver, is some situations, the user will have to interpret more dimensions of disagreement. To do so, the user can access all the results of the PCA as provided by the `PCA` function of the `FactoMineR` package (cf. help page of this function if needed). These results can be accessed with this code:

```{r}
res.pedag$res.pca
```

We can draw a bar plot with the eigenvalues of PCA with the following code:

<center>
```{r fig.width=6, fig.height=3, dpi=400}
barplot(res.pedag$res.pca$eig[, 1], main = "Eigenvalues", names.arg = paste0("Dim", 1 : nrow(res.pedag$res.pca$eig)))
```
</center>

This graph allows to detect the number of dimensions interesting for the interpretation of the structure of disagreement. The user can then plot the graph for the other interesting dimensions, let's say the third and the fourth dimensions (even if in our case, they should not be interpreted):

```{r eval=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", axis = c(3, 4))
```

```{r echo=FALSE, fig.width=8, dpi=400, fig.height=5, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", axis = c(3, 4), col.clust = c("#42B983", "#F36170"))
```

The `plot.AgreeClust` allows to plot the multidimensional representation of the structure of disagreement in an interative way. By moving the cursor on a point, several pieces of information are printed:

```{r eval=FALSE, fig.width=8, dpi=400, fig.height=5, message=FALSE, results=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", interact = TRUE)
```

```{r echo=FALSE, fig.width=10, fig.height=6, warning=FALSE, message=FALSE}
plot.AgreeClust(res.pedag, choice = "mul", interact = TRUE, col.clust = c("#42B983", "#F36170"), vignette = TRUE)
```

Finally, the function provides an automatic description of the clusters of raters. This description can be accessed with this code: 

```{r results=FALSE}
res.pedag$charact.clust
```

As shown on the following output, cluster 1 is composed of 10 raters (50/% of the panel) and the most representative rater of this cluster is *Subj10*. In this cluster, and relatively to the average, women and raters between 21 and 30 years old are overrepresented; while men and raters who assessed their frequency of use of the category of product at 3/10 are underrepresented. Relatively to the average, raters of this cluster gave higher ratings to stimuli presenting a high intensity of citrus fruits flavor and to stimuli with the prototype packaging; while they gave lower ratings to stimuli presenting a high intensity of wood flavor and to stimuli with the current packaging:

```{r echo=FALSE}
res.pedag$charact.clust[[1]]
```

As there is only two clusters of raters in this example, the interpretation of cluster 2 is the opposite to those of cluster 1:

```{r echo=FALSE}
res.pedag$charact.clust[[2]]
```

A real data set of continuous ratings is also available in the help page of the package. This data set corresponds to hedonic data obtained during an experiment where 16 cocktails have been evaluated on a structured scale from 0 to 10, by 100 consumers, according to their liking (0) or disliking (10). However, as the computation of the tests for the significance of the levels of the dendrogram can be time-consuming, its analysis is not presented in this vignette This analysis can be accessed with this code:

```{r eval=FALSE}
library(SensoMineR)
data(cocktail)
res.cocktail <- AgreeClustCont(dta = hedo.cocktail)
res.cocktail
```

# Conclusion

The main features of the `AgreeClust` package have been explained and illustrated in this vignette, using pedagogic data sets that are available in the package.

# References

Husson, F., Lê, S., & Pagès, J. (2011) Exploratory multivariate analysis by example using R. CRC Press.

Lê, S., Josse, J., & Husson, F. (2008) FactoMineR: an R package for multivariate analysis. Journal of Statistical Software, 25(1).
